{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc8a376",
   "metadata": {},
   "source": [
    "## Assignment 5 - Group 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e9f4f",
   "metadata": {},
   "source": [
    "### First, we install all packages necesary and the chrome driver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a94e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links \n",
    "# chromedriver= win 64: https://googlechromelabs.github.io/chrome-for-testing/\n",
    "# chromedriver= win 32 :  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/120.0.6099.109/win32/chromedriver-win32.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b431376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rafae\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e458df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager==3.4.2 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from webdriver_manager==3.4.2) (2.31.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from webdriver_manager==3.4.2) (6.0.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from webdriver_manager==3.4.2) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from crayons->webdriver_manager==3.4.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager==3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0bdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we import each library and install each package necesary to do the web scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import unidecode\n",
    "import time \n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b22c34",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PRESIDENCIAL 2021 - 2DA VUELTA\n",
      "2 PRESIDENCIAL 2021\n",
      "3 PRESIDENCIAL 2016 - 2DA VUELTA\n",
      "4 PRESIDENCIAL 2016\n",
      "5 PRESIDENCIAL 2011 - 2DA VUELTA\n",
      "6 PRESIDENCIAL 2011\n",
      "7 PRESIDENCIAL 2006 - 2DA VUELTA\n",
      "8 PRESIDENCIAL 2006\n",
      "9 PRESIDENCIAL 2001 - 2DA VUELTA\n",
      "10 PRESIDENCIAL 2001\n",
      "11 PRESIDENCIAL 2000 - 2DA VUELTA\n",
      "12 PRESIDENCIAL 2000\n",
      "13 PRESIDENCIAL 1995\n",
      "14 PRESIDENCIAL 1990 - 2DA VUELTA\n",
      "15 PRESIDENCIAL 1990\n",
      "16 PRESIDENCIAL 1985\n",
      "17 PRESIDENCIAL 1980\n",
      "18 PRESIDENCIAL 1963\n",
      "19 PRESIDENCIAL 1962\n",
      "20 PRESIDENCIAL 1956\n",
      "21 PRESIDENCIAL 1950\n",
      "22 PRESIDENCIAL 1945\n",
      "23 PRESIDENCIAL 1939\n",
      "24 PRESIDENCIAL 1936\n",
      "25 PRESIDENCIAL 1931\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organización Política</th>\n",
       "      <th>Símbolo</th>\n",
       "      <th>Plan de Gobierno</th>\n",
       "      <th>Total Votos</th>\n",
       "      <th>Porcentaje Votos Válidos</th>\n",
       "      <th>Lista de Candidatos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARTIDO POLITICO NACIONAL PERU LIBRE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8,836,380</td>\n",
       "      <td>50.126%</td>\n",
       "      <td>VER LISTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUERZA POPULAR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8,792,117</td>\n",
       "      <td>49.874%</td>\n",
       "      <td>VER LISTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VOTOS EN BLANCO</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>121,489</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VOTOS NULOS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1,106,816</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Organización Política Símbolo Plan de Gobierno Total Votos  \\\n",
       "0                                  None    None             None        None   \n",
       "1  PARTIDO POLITICO NACIONAL PERU LIBRE                            8,836,380   \n",
       "2                        FUERZA POPULAR                            8,792,117   \n",
       "3                       VOTOS EN BLANCO                              121,489   \n",
       "4                           VOTOS NULOS                            1,106,816   \n",
       "\n",
       "  Porcentaje Votos Válidos Lista de Candidatos  \n",
       "0                     None                None  \n",
       "1                  50.126%          VER LISTA   \n",
       "2                  49.874%          VER LISTA   \n",
       "3                                               \n",
       "4                                               "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we install the extention in order to access to the page we want\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# We also maximize the window\n",
    "driver.maximize_window()\n",
    "\n",
    "# We create an empty list to store DataFrames\n",
    "all_table_data = []\n",
    "\n",
    "# Here, we define the URL to be visited\n",
    "url = 'https://infogob.jne.gob.pe/Eleccion'\n",
    "\n",
    "# And open the specified URL in the Chrome browser\n",
    "driver.get(url)\n",
    "\n",
    "# Find and click on the dropdown element using XPath\n",
    "dropdown = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div')\n",
    "dropdown.click()\n",
    "\n",
    "# Introduce a delay to wait for the dropdown options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the option for presidential elections within the dropdown\n",
    "elec_presidenciales = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div/div[2]/div[2]')\n",
    "elec_presidenciales.click()\n",
    "\n",
    "# Introduce a delay to wait for the next set of options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the element corresponding to the election year\n",
    "año_eleccion = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div')\n",
    "año_eleccion.click()\n",
    "\n",
    "# Introduce a delay to wait for the election year options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the specific election year option using format\n",
    "año_eleccion = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div/div[2]/div[{}]'.format(2))\n",
    "año_eleccion.click()\n",
    "\n",
    "# Store the text content of the selected election year type\n",
    "año_eleccion_tipo = año_eleccion.text\n",
    "\n",
    "# Introduce a delay for stability before proceeding\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "# Get all elements of province\n",
    "election_select = Select(driver.find_element(By.ID, \"IdEleccion\"))\n",
    "num_election_options = len(election_select.options)\n",
    "\n",
    "for elec_idx in range(1, num_election_options):\n",
    "    # Get the election options again since HTML may be refreshing\n",
    "    election_select = Select(driver.find_element(By.ID, \"IdEleccion\"))\n",
    "    \n",
    "    # Get the individual option\n",
    "    election_option = election_select.options[elec_idx]\n",
    "\n",
    "    # Get the option name of each election\n",
    "    elec_name = election_option.get_attribute(\"text\")\n",
    "    \n",
    "    print(elec_idx, elec_name)\n",
    "    \n",
    "    # Click the \"Selecciona\" button for each election\n",
    "    selecciona = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[3]/div/button')\n",
    "    selecciona.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Navigate to the final page for each election\n",
    "    pag_final = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[3]/div[1]/ul/li[2]/a')\n",
    "    pag_final.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Obtain page's HTML\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # Use BeautifulSoup to analize HTML\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    data_table = soup.find('table', {'class': 'table'})\n",
    "    \n",
    "    # Extract data from table and store it\n",
    "    table_data = []\n",
    "    for row in data_table.find_all('tr'):\n",
    "        row_data = [cell.text for cell in row.find_all('td')]\n",
    "        table_data.append(row_data)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    table_path = driver.find_element(By.ID, 'gridEleccionResultadosElectorales')\n",
    "    table_html = table_path.get_attribute ('innerHTML')\n",
    "    table = pd.read_html(table_html)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Append the table data to the list\n",
    "    all_table_data.append(table_data)\n",
    "    \n",
    "    # Go back to the previous page\n",
    "    driver.back()\n",
    "    driver.back()\n",
    "\n",
    "# After the loop, we create a DataFrame from all_table_data\n",
    "flat_table_data = [item for sublist in all_table_data for item in sublist]\n",
    "\n",
    "# Then we create the DataFrame\n",
    "column_names = ['Organización Política', 'Símbolo', 'Plan de Gobierno', 'Total Votos', 'Porcentaje Votos Válidos', 'Lista de Candidatos']\n",
    "df = pd.DataFrame(table_data, columns=column_names)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "260eaa20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PRESIDENCIAL 2021 - 2DA VUELTA\n",
      "2 PRESIDENCIAL 2021\n",
      "                  Organización Política Símbolo Plan de Gobierno Total Votos  \\\n",
      "0                                  None    None             None        None   \n",
      "1  PARTIDO POLITICO NACIONAL PERU LIBRE                            8,836,380   \n",
      "2                        FUERZA POPULAR                            8,792,117   \n",
      "3                       VOTOS EN BLANCO                              121,489   \n",
      "4                           VOTOS NULOS                            1,106,816   \n",
      "5                                  None    None             None        None   \n",
      "6  PARTIDO POLITICO NACIONAL PERU LIBRE                            8,836,380   \n",
      "7                        FUERZA POPULAR                            8,792,117   \n",
      "8                       VOTOS EN BLANCO                              121,489   \n",
      "9                           VOTOS NULOS                            1,106,816   \n",
      "\n",
      "  Porcentaje Votos Válidos Lista de Candidatos  \n",
      "0                     None                None  \n",
      "1                  50.126%          VER LISTA   \n",
      "2                  49.874%          VER LISTA   \n",
      "3                                               \n",
      "4                                               \n",
      "5                     None                None  \n",
      "6                  50.126%          VER LISTA   \n",
      "7                  49.874%          VER LISTA   \n",
      "8                                               \n",
      "9                                               \n"
     ]
    }
   ],
   "source": [
    "# Now, we install the extention in order to access to the page we want\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# We also maximize the window\n",
    "driver.maximize_window()\n",
    "\n",
    "# We create an empty list to store DataFrames\n",
    "all_table_data = []\n",
    "\n",
    "# Here, we define the URL to be visited\n",
    "url = 'https://infogob.jne.gob.pe/Eleccion'\n",
    "\n",
    "# And open the specified URL in the Chrome browser\n",
    "driver.get(url)\n",
    "\n",
    "# Find and click on the dropdown element using XPath\n",
    "dropdown = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div')\n",
    "dropdown.click()\n",
    "\n",
    "# Introduce a delay to wait for the dropdown options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the option for presidential elections within the dropdown\n",
    "elec_presidenciales = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div/div[2]/div[2]')\n",
    "elec_presidenciales.click()\n",
    "\n",
    "# Introduce a delay to wait for the next set of options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the element corresponding to the election year\n",
    "año_eleccion = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div')\n",
    "año_eleccion.click()\n",
    "\n",
    "# Introduce a delay to wait for the election year options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the specific election year option using format\n",
    "año_eleccion = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div/div[2]/div[{}]'.format(2))\n",
    "año_eleccion.click()\n",
    "\n",
    "# Store the text content of the selected election year type\n",
    "año_eleccion_tipo = año_eleccion.text\n",
    "\n",
    "# Introduce a delay for stability before proceeding\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "# Get all elements of province\n",
    "election_select = Select(driver.find_element(By.ID, \"IdEleccion\"))\n",
    "num_election_options = len(election_select.options)\n",
    "\n",
    "for elec_idx in range(1, num_election_options):\n",
    "    # Get the election options again since HTML may be refreshing\n",
    "    election_select = Select(driver.find_element(By.ID, \"IdEleccion\"))\n",
    "    \n",
    "    # Get the individual option\n",
    "    election_option = election_select.options[elec_idx]\n",
    "\n",
    "    # Get the option name of each election\n",
    "    elec_name = election_option.get_attribute(\"text\")\n",
    "    \n",
    "    print(elec_idx, elec_name)\n",
    "    \n",
    "    # Click the \"Selecciona\" button for each election\n",
    "    selecciona = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[3]/div/button')\n",
    "    selecciona.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Navigate to the final page for each election\n",
    "    pag_final = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[3]/div[1]/ul/li[2]/a')\n",
    "    pag_final.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Obtain page's HTML\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # Use BeautifulSoup to analize HTML\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    data_table = soup.find('table', {'class': 'table'})\n",
    "    \n",
    "    # Extract data from table and store it\n",
    "    table_data = []\n",
    "    for row in data_table.find_all('tr'):\n",
    "        row_data = [cell.text for cell in row.find_all('td')]\n",
    "        table_data.append(row_data)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    We didn't use this code to extract the data since it failed to recognize the HTML within the table class.\n",
    "    \n",
    "    table_path = driver.find_element(By.ID, 'gridEleccionResultadosElectorales')\n",
    "    table_html = table_path.get_attribute ('innerHTML')\n",
    "    table = pd.read_html(table_html)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Append the table data to the list of DataFrames\n",
    "    column_names = ['Organización Política', 'Símbolo', 'Plan de Gobierno', 'Total Votos', 'Porcentaje Votos Válidos', 'Lista de Candidatos']\n",
    "    df_iteration = pd.DataFrame(table_data, columns=column_names)\n",
    "    all_table_data.append(df_iteration)\n",
    "    \n",
    "    # Go back to the previous page\n",
    "    driver.back()\n",
    "    driver.back()\n",
    "\n",
    "# After the loop,we convert the list of DataFrames into a single DataFrame\n",
    "df = pd.concat(all_table_data, ignore_index=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7467d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we import each library and install each package necesary to do the web scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import unidecode\n",
    "import time \n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ced48",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "all_table_data = []\n",
    "\n",
    "\n",
    "url = 'https://infogob.jne.gob.pe/Eleccion'\n",
    "\n",
    "# And open the specified URL in the Chrome browser\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "for i in range(2,4):\n",
    "\n",
    "    driver.get(url)\n",
    "    dropdown = driver.find_element(By.XPATH,'/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div')\n",
    "    dropdown.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    elec_presidenciales = driver.find_element(By.XPATH,'/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div/div[2]/div[2]')\n",
    "    elec_presidenciales.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    año_eleccion=driver.find_element(By.XPATH,'/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div')\n",
    "    año_eleccion.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    año_eleccion = driver.find_element(By.XPATH,'/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div/div[2]/div[{}]'.format(i))\n",
    "    año_eleccion.click()\n",
    "    año_eleccion_tipo = año_eleccion.text\n",
    "    time.sleep(1)\n",
    "\n",
    "    selecciona = driver.find_element(By.XPATH,'/html/body/div[1]/section/div[2]/div[2]/div[3]/div/button')\n",
    "    selecciona.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    pag_final=driver.find_element(By.XPATH,'/html/body/div[1]/section/div[2]/div[3]/div[1]/ul/li[2]/a')\n",
    "    pag_final.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Obtain page's HTML\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # Use BeautifulSoup to analize HTML\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    data_table = soup.find('table', {'class': 'table'})\n",
    "    \n",
    "    # Extract data from table and store it\n",
    "    table_data = []\n",
    "    for row in data_table.find_all('tr'):\n",
    "        row_data = [cell.text for cell in row.find_all('td')]\n",
    "        table_data.append(row_data)\n",
    "        \n",
    "    \n",
    "    # Append the table data to the list\n",
    "    all_table_data.append(table_data)\n",
    "    \n",
    "    # Go back to the previous page\n",
    "    driver.back()\n",
    "    driver.back()\n",
    "\n",
    "# After the loop, we create a DataFrame from all_table_data\n",
    "flat_table_data = [item for sublist in all_table_data for item in sublist]\n",
    "\n",
    "# Then we create the DataFrame\n",
    "column_names = ['Organización Política', 'Símbolo', 'Plan de Gobierno', 'Total Votos', 'Porcentaje Votos Válidos', 'Lista de Candidatos']\n",
    "df = pd.DataFrame(table_data, columns=column_names)\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
