{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc8a376",
   "metadata": {},
   "source": [
    "## Assignment 5 - Group 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e9f4f",
   "metadata": {},
   "source": [
    "### First, we install all packages necesary and the chrome driver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a94e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links \n",
    "# chromedriver= win 64: https://googlechromelabs.github.io/chrome-for-testing/\n",
    "# chromedriver= win 32 :  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/120.0.6099.109/win32/chromedriver-win32.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60882e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in c:\\users\\rafae\\anaconda3\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b431376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rafae\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e458df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager==3.4.2 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from webdriver_manager==3.4.2) (2.31.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from webdriver_manager==3.4.2) (6.0.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from webdriver_manager==3.4.2) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from crayons->webdriver_manager==3.4.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rafae\\anaconda3\\lib\\site-packages (from requests->webdriver_manager==3.4.2) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager==3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0bdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we import each library and install each package necesary to do the web scrapping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import unidecode\n",
    "import time \n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b22c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PRESIDENCIAL 2021 - 2DA VUELTA\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 90\u001b[0m\n\u001b[0;32m     87\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Now, you can use pandas to read the HTML table\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(\u001b[38;5;28mstr\u001b[39m(table))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Print or further process the DataFrame\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[0;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m   1210\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1213\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1214\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1215\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1216\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1217\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1218\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1219\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1220\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1221\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1222\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1223\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1224\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1225\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1226\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1227\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1228\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1229\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1230\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1001\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m-> 1001\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[0;32m   1003\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:981\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    978\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 981\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:257\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:613\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[1;34m(self, doc, match, attrs)\u001b[0m\n\u001b[0;32m    610\u001b[0m tables \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[1;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    615\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    616\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "# Now, we install the extention in order to access to the page we want\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# We also maximize the window\n",
    "driver.maximize_window()\n",
    "\n",
    "# We create an empty list to store DataFrames\n",
    "dataframes_list = []\n",
    "\n",
    "# Here, we define the URL to be visited\n",
    "url = 'https://infogob.jne.gob.pe/Eleccion'\n",
    "\n",
    "# And open the specified URL in the Chrome browser\n",
    "driver.get(url)\n",
    "\n",
    "# Find and click on the dropdown element using XPath\n",
    "dropdown = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div')\n",
    "dropdown.click()\n",
    "\n",
    "# Introduce a delay to wait for the dropdown options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the option for presidential elections within the dropdown\n",
    "elec_presidenciales = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[1]/div/div[2]/div[2]')\n",
    "elec_presidenciales.click()\n",
    "\n",
    "# Introduce a delay to wait for the next set of options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the element corresponding to the election year\n",
    "año_eleccion = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div')\n",
    "año_eleccion.click()\n",
    "\n",
    "# Introduce a delay to wait for the election year options to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and click on the specific election year option using format\n",
    "año_eleccion = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[2]/div[2]/div/div[2]/div[{}]'.format(2))\n",
    "año_eleccion.click()\n",
    "\n",
    "# Store the text content of the selected election year type\n",
    "año_eleccion_tipo = año_eleccion.text\n",
    "\n",
    "# Introduce a delay for stability before proceeding\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "# Get all elements of province\n",
    "election_select = Select(driver.find_element(By.ID, \"IdEleccion\"))\n",
    "num_election_options = len(election_select.options)\n",
    "\n",
    "for elec_idx in range(1, num_election_options):\n",
    "    # Get the election options again since HTML may be refreshing\n",
    "    election_select = Select(driver.find_element(By.ID, \"IdEleccion\"))\n",
    "    \n",
    "    # Get the individual option\n",
    "    election_option = election_select.options[elec_idx]\n",
    "\n",
    "    # Get the option name of each election\n",
    "    elec_name = election_option.get_attribute(\"text\")\n",
    "    \n",
    "    print(elec_idx, elec_name)\n",
    "    \n",
    "    # Click the \"Selecciona\" button for each election\n",
    "    selecciona = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[2]/div[3]/div/button')\n",
    "    selecciona.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Navigate to the final page for each election\n",
    "    pag_final = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[2]/div[3]/div[1]/ul/li[2]/a')\n",
    "    pag_final.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    table_path = driver.find_element(By.ID, 'gridEleccionResultadosElectorales')\n",
    "    table_html = table_path.get_attribute ('innerHTML')\n",
    "    table = pd.read_html(table_html)\n",
    "    \n",
    "    # Go back to the previous page\n",
    "    driver.back()\n",
    "    driver.back()\n",
    "\n",
    "# Print all data as needed\n",
    " print(dataframes_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
